#!/usr/bin/env python
# video_analyzer_hd.py
# HD í•´ìƒë„ë¡œ ë¹„ë””ì˜¤ íŒŒì¼ì„ ì´ˆë‹¹ 1í”„ë ˆì„ ë¶„ì„í•˜ì—¬ ê²°ê³¼ ì €ì¥

import os
import cv2
import time
import inspect
import argparse
import json
from pathlib import Path
from datetime import datetime, timedelta
import numpy as np
from PIL import Image
from torchvision import transforms
import torch
import onnxruntime as ort

# LWCC ìºì‹œ ë””ë ‰í† ë¦¬ë¥¼ í™ˆ ë””ë ‰í† ë¦¬ë¡œ ì„¤ì •
os.environ['HOME'] = os.path.expanduser('~')
home_dir = os.path.expanduser('~')
lwcc_cache_dir = os.path.join(home_dir, '.lwcc')
os.makedirs(lwcc_cache_dir, exist_ok=True)
os.makedirs(os.path.join(lwcc_cache_dir, 'weights'), exist_ok=True)

# LWCC ê´€ë ¨ í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
os.environ['LWCC_CACHE_DIR'] = lwcc_cache_dir
os.environ['TORCH_HOME'] = lwcc_cache_dir
os.environ['XDG_CACHE_HOME'] = lwcc_cache_dir

from lwcc import LWCC

# â”€â”€â”€ ê¸€ë¡œë²Œ ë³€ìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
HD_RESOLUTION = (1280, 720)  # HD í•´ìƒë„
model = None
device = None
ort_session = None  # ONNX Runtime ì„¸ì…˜ì„ ìœ„í•œ ì „ì—­ ë³€ìˆ˜

def initialize_model(use_gpu=False):
    """LWCC ëª¨ë¸ ì´ˆê¸°í™” (PyTorch ë²„ì „)"""
    global model, device

    # ë””ë°”ì´ìŠ¤ ì„¤ì •
    if use_gpu and torch.cuda.is_available():
        device = torch.device("cuda")
        print("ğŸ”§ GPU ì‚¬ìš© (HD ìµœì í™”)")
    else:
        device = torch.device("cpu")
        print("ğŸ”§ CPU ì‚¬ìš© (HD í•´ìƒë„)")

    # ëª¨ë¸ ë¡œë“œ
    print(f"ğŸ“¥ LWCC PyTorch ëª¨ë¸ ë¡œë”© ì¤‘... (HD {HD_RESOLUTION[0]}x{HD_RESOLUTION[1]})")
    mdl_kwargs = dict(model_name="DM-Count", model_weights="SHA")
    if 'device' in inspect.signature(LWCC.load_model).parameters:
        mdl_kwargs['device'] = device

    model = LWCC.load_model(**mdl_kwargs).to(device).eval()
    print("âœ… LWCC ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")


def initialize_onnx_model(use_gpu: bool = False, model_path: str = None):
    """
    ONNX Runtime ì„¸ì…˜ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
    - use_gpu: CUDA providerë¥¼ ì“¸ì§€ ì—¬ë¶€
    - model_path: ë¡œë“œí•  ONNX íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸: onnx_models/lwcc_dm_count.onnx)
    """
    global ort_session
    default_path = Path("onnx_models/lwcc_dm_count.onnx")
    model_path = Path(model_path) if model_path else default_path

    if not model_path.exists():
        raise FileNotFoundError(f"ONNX ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")

    available = ort.get_available_providers()
    if use_gpu and "CUDAExecutionProvider" in available:
        providers = ["CUDAExecutionProvider"]
    else:
        if use_gpu:
            print("âš ï¸ CUDAExecutionProvider ë¯¸ì‚¬ìš©(ì‚¬ìš© ë¶ˆê°€). CPUExecutionProviderë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
        providers = ["CPUExecutionProvider"]

    print(f"ğŸ”– ONNXRuntime providers ì„ íƒ: {providers}")
    sess_options = ort.SessionOptions()
    ort_session = ort.InferenceSession(str(model_path), sess_options, providers=providers)
    print(f"âœ… ort_session ì´ˆê¸°í™” ì™„ë£Œ: model={model_path.name}")


def analyze_frame_hd(frame, already_hd=False):
    """
    OpenCV í”„ë ˆì„ì„ HD í•´ìƒë„ë¡œ ë¦¬ì‚¬ì´ì§• í›„
    PyTorch LWCC ëª¨ë¸ë¡œ ì¸ì›ìˆ˜ ë¶„ì„
    """
    try:
        start_time = time.time()

        # HD í•´ìƒë„ë¡œ ë¦¬ì‚¬ì´ì§•
        hd_frame = frame if already_hd else cv2.resize(frame, HD_RESOLUTION)

        # BGR -> PIL(RGB)
        pil_img = Image.fromarray(cv2.cvtColor(hd_frame, cv2.COLOR_BGR2RGB))

        # ëª¨ë¸ ì „ì²˜ë¦¬ (long side 1000 ê¸°ì¤€ ë¦¬ì‚¬ì´ì§•)
        long = max(pil_img.size)
        factor = 1000 / long
        resized_img = pil_img.resize(
            (int(pil_img.size[0] * factor), int(pil_img.size[1] * factor)),
            Image.BILINEAR
        )

        # ToTensor & Normalize
        trans = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406],
                                 [0.229, 0.224, 0.225])
        ])
        img_tensor = trans(resized_img).unsqueeze(0).to(device)

        torch.cuda.empty_cache() if torch.cuda.is_available() else None
        with torch.no_grad():
            output = model(img_tensor)

        density = output[0, 0].detach().cpu().numpy()
        count = float(density.sum())
        processing_time = time.time() - start_time
        return count, processing_time

    except Exception as e:
        print(f"âŒ í”„ë ˆì„ ë¶„ì„ ì˜¤ë¥˜: {e}")
        return None, 0


def analyze_frame_onnx(frame, already_hd=False):
    """
    ONNX Runtimeì„ ì‚¬ìš©í•˜ì—¬ í”„ë ˆì„ ì¸ì›ìˆ˜ ë¶„ì„
    """
    global ort_session
    if ort_session is None:
        raise RuntimeError("ONNX Runtime ì„¸ì…˜ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. initialize_onnx_model()ì„ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”.")

    try:
        start_time = time.time()
        hd_frame = frame if already_hd else cv2.resize(frame, HD_RESOLUTION)
        pil_img = Image.fromarray(cv2.cvtColor(hd_frame, cv2.COLOR_BGR2RGB))

        long = max(pil_img.size)
        factor = 1000 / long
        resized_img = pil_img.resize(
            (int(pil_img.size[0] * factor), int(pil_img.size[1] * factor)),
            Image.BILINEAR
        )

        trans = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406],
                                 [0.229, 0.224, 0.225])
        ])
        img_tensor = trans(resized_img).unsqueeze(0)

        ort_inputs = {ort_session.get_inputs()[0].name: img_tensor.numpy()}
        ort_outs = ort_session.run(None, ort_inputs)
        density = ort_outs[0][0, 0]
        count = float(density.sum())
        processing_time = time.time() - start_time
        return count, processing_time

    except Exception as e:
        print(f"âŒ ONNX í”„ë ˆì„ ë¶„ì„ ì˜¤ë¥˜: {e}")
        return None, 0


def analyze_batch_onnx(frames):
    """
    ONNX Runtimeì„ ì‚¬ìš©í•˜ì—¬ ì—¬ëŸ¬ í”„ë ˆì„ ë°°ì¹˜ ë¶„ì„
    """
    global ort_session
    if ort_session is None:
        raise RuntimeError("ONNX Runtime ì„¸ì…˜ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    if not frames:
        return []

    try:
        # ì „ì²˜ë¦¬
        trans = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406],
                                 [0.229, 0.224, 0.225])
        ])
        tensors = []
        for frame in frames:
            pil_img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
            long = max(pil_img.size)
            factor = 1000 / long
            resized_img = pil_img.resize(
                (int(pil_img.size[0] * factor), int(pil_img.size[1] * factor)),
                Image.BILINEAR
            )
            tensors.append(trans(resized_img))

        batch = torch.stack(tensors).numpy()
        ort_inputs = {ort_session.get_inputs()[0].name: batch}
        ort_outs = ort_session.run(None, ort_inputs)

        counts = np.sum(ort_outs[0], axis=(2, 3)).flatten().tolist()
        return counts

    except Exception as e:
        print(f"âŒ ONNX ë°°ì¹˜ ë¶„ì„ ì˜¤ë¥˜: {e}")
        return [None] * len(frames)


def analyze_video_hd(video_path, output_dir, temp_dir):
    """HD í•´ìƒë„ë¡œ ë¹„ë””ì˜¤ ë¶„ì„ (ì´ˆë‹¹ 1í”„ë ˆì„) + ê²°ê³¼ ì €ì¥"""
    video_name = Path(video_path).stem
    print(f"\nğŸ¬ [{video_name}] HD ë¶„ì„ ì‹œì‘...")

    # ì¶œë ¥ íŒŒì¼
    txt_file  = Path(output_dir) / f"{video_name}_hd_analysis.txt"
    csv_file  = Path(output_dir) / f"{video_name}_hd_analysis.csv"
    json_file = Path(output_dir) / f"{video_name}_hd_analysis.json"

    cap = cv2.VideoCapture(str(video_path))
    if not cap.isOpened():
        print(f"âŒ [{video_name}] ë¹„ë””ì˜¤ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    fps          = cap.get(cv2.CAP_PROP_FPS) or 30.0
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    duration     = total_frames / fps

    print(f"ğŸ“¹ ì›ë³¸ FPS: {fps:.1f}, ì´ í”„ë ˆì„: {total_frames}, ê¸¸ì´: {duration:.1f}ì´ˆ")
    print(f"ğŸ“º HD í•´ìƒë„: {HD_RESOLUTION[0]}x{HD_RESOLUTION[1]}")
    print("ğŸ¯ ë¶„ì„ ê°„ê²©: 1ì´ˆë‹¹ 1í”„ë ˆì„")

    results = []
    frame_interval = int(fps)
    total_seconds  = int(duration)

    for second in range(total_seconds + 1):
        frame_number = second * frame_interval
        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)
        ret, frame = cap.read()
        if not ret:
            break

        count, proc_time = analyze_frame_hd(frame)
        if count is not None:
            ts = str(timedelta(seconds=second))
            results.append({
                'second': second,
                'timestamp': ts,
                'frame_number': frame_number,
                'count': round(count, 1),
                'count_int': int(round(count)),
                'process_time': round(proc_time, 3),
                'resolution': f"{HD_RESOLUTION[0]}x{HD_RESOLUTION[1]}"
            })
            print(f"ğŸ¯ [{video_name}] {ts} | ğŸ‘¥ {count:.1f}ëª… | â±ï¸ {proc_time:.3f}ì´ˆ")
        else:
            print(f"âŒ [{video_name}] {second}ì´ˆ ë¶„ì„ ì‹¤íŒ¨")

    cap.release()

    # ê²°ê³¼ ì €ì¥
    print("\nğŸ’¾ ê²°ê³¼ ì €ì¥ ì¤‘...")
    with open(txt_file, 'w', encoding='utf-8') as f:
        f.write(f"HD LWCC ë¹„ë””ì˜¤ ì¸ì›ìˆ˜ ë¶„ì„ ê²°ê³¼\níŒŒì¼: {video_name}\n")
        for r in results:
            f.write(f"{r['timestamp']} | {r['count']}ëª… | {r['process_time']}ì´ˆ\n")

    with open(csv_file, 'w', encoding='utf-8') as f:
        f.write("ì´ˆ,íƒ€ì„ìŠ¤íƒ¬í”„,í”„ë ˆì„ë²ˆí˜¸,ì¸ì›ìˆ˜,ì •ìˆ˜ì¸ì›ìˆ˜,ì²˜ë¦¬ì‹œê°„,í•´ìƒë„\n")
        for r in results:
            f.write(f"{r['second']},{r['timestamp']},{r['frame_number']},"
                    f"{r['count']},{r['count_int']},{r['process_time']},{r['resolution']}\n")

    analysis_data = {
        'video_info': {
            'filename': video_name, 'fps': fps,
            'total_frames': total_frames,
            'duration_seconds': duration,
            'resolution': f"{HD_RESOLUTION[0]}x{HD_RESOLUTION[1]}"
        },
        'analysis_info': {
            'analysis_time': datetime.now().isoformat(),
            'frame_interval': frame_interval,
            'total_analyzed_frames': len(results)
        },
        'results': results
    }
    with open(json_file, 'w', encoding='utf-8') as f:
        json.dump(analysis_data, f, ensure_ascii=False, indent=2)

    # ìš”ì•½ ì¶œë ¥
    if results:
        avg = sum(r['count'] for r in results) / len(results)
        print(f"\nğŸ“Š [{video_name}] ë¶„ì„ ì™„ë£Œ! í‰ê·  ì¸ì›ìˆ˜: {avg:.1f}ëª…")
    return analysis_data


def main():
    parser = argparse.ArgumentParser("HD LWCC Video Analyzer")
    parser.add_argument("--video-dir",   default="video",     help="ë¹„ë””ì˜¤ íŒŒì¼ í´ë”")
    parser.add_argument("--output-dir",  default="results_hd", help="ê²°ê³¼ ì €ì¥ í´ë”")
    parser.add_argument("--use-gpu",     action="store_true", help="GPU ì‚¬ìš©")
    parser.add_argument("--temp-dir",    default="/tmp",       help="ì„ì‹œ íŒŒì¼ ì €ì¥ ê²½ë¡œ")
    args = parser.parse_args()

    print("ğŸ¯ HD LWCC ë¹„ë””ì˜¤ ì¸ì›ìˆ˜ ë¶„ì„ê¸°")
    initialize_model(args.use_gpu)

    out_dir = Path(args.output_dir)
    out_dir.mkdir(exist_ok=True)

    videos = []
    for ext in ['*.mp4','*.avi','*.mov','*.mkv','*.flv','*.wmv']:
        videos += list(Path(args.video_dir).glob(ext))
    if not videos:
        print(f"âŒ ë¹„ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {args.video_dir}")
        return

    for i, vp in enumerate(videos, 1):
        print(f"\n[{i}/{len(videos)}] {vp.name}")
        analyze_video_hd(vp, out_dir, args.temp_dir)

    print(f"\nğŸ‰ ëª¨ë“  ë¹„ë””ì˜¤ ë¶„ì„ ì™„ë£Œ! ê²°ê³¼ í´ë”: {out_dir}")


if __name__ == "__main__":
    main()
